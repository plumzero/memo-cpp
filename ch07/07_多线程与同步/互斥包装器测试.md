
## 对 std::lock_guard 与 std::unique_lock 的测试分析

#### std::lock_guard
- 说明
    + 在构造函数中进行加锁，析构函数中进行解锁；
    + 除此之外，没有其他的加锁或解锁方法；
    + 仅就个人而言，更多的是使用 std::unique_lock, 而非 std::lock_guard;
- 示例程序
    + [lock_guard](t/02_lock_guard.cpp)
    + 创建 20 条线程，执行 10000 次加法，期望这 10000 次加法均匀分配到这 20 条线程中执行运算
- 执行结果分析
    + 运行结果如下
      ```shell
        sum=50005000
        139920848946944 : 8782
        139920857339648 : 1
        139920865732352 : 1
        139920874125056 : 1
        139920882517760 : 1
        139920890910464 : 1
        139920899303168 : 1
        139920907695872 : 1
        139920991557376 : 1
        139920999950080 : 1
        139921008342784 : 1
        139921016735488 : 1
        139921025128192 : 1
        139921033520896 : 1
        139921041913600 : 1
        139921123546880 : 2
        139921131939584 : 1
        139921140332288 : 1
        139921148724992 : 482
        139921157117696 : 738
        counter=10020
      ```
    + 通过运行结果，可以看到有两个问题值得关注:
        + 1. 结果并不符合预期，大部分线程只执行了一次
        + 2. 本应执行 10000 次，但统计却多了 20 次
    + 对于 1，因为 std::lock_guard 的加锁或解锁方式，在一个作用域完成之后，锁就应该被释放，这个时候其他等待的线程就可以获得这把锁接力执行。但可能是系统线程调度方式并不是理想，或者其他原因，刚刚执行过的线程再次竞得这把锁连续执行，导致其他线程一直在等待；
    + std::lock_guard 的加锁和解锁都是在作用域的边界处执行，也就是说，在释放锁之后，它立即会进入下一个竞锁周期，这样是不是比其他线程更易获得这把锁呢？
    + 如果在对关键区的保护完毕之后立即释放锁，而不是通过作用域析构方式，当前线程在释放锁之后会继续执行一段时间，这段时间内，其他线程会不会比当前线程要先获得这把锁呢？
    + 对于 2，只有两三个线程在忙，其他的线程因为竞不到锁只能等待，等到其他线程忙完退出循环之后，等待线程依次获得这把锁，但条件已不满足，于是也退出线程。这可以通过在 add 的 if...else 中分别统计进行验证。

#### std::unique_lock
- 说明
    + 和 std::lock_guard 一样，也可以在构造函数中进行加锁，析构函数中进行解锁；
    + 提供了更灵活的加锁或解锁方法；
- 示例程序
    + [unique_lock](t/02_unique_lock.cpp)
    + 执行场景1: 同 std::lock_guard
    + 执行场景2: 退出关键区后立即释放锁
    + 执行场景3: 退出关键区后立即释放锁，同时休眠一段时间模拟工作
- 执行结果分析
    + 执行场景 1 和 2 运行结果如下
      ```shell
        sum=50005000
        140506432534272 : 1
        140506516395776 : 1
        140506524788480 : 1
        140506533181184 : 1
        140506541573888 : 1
        140506549966592 : 1
        140506558359296 : 1
        140506566752000 : 1
        140506650613504 : 1
        140506659006208 : 1
        140506667398912 : 1
        140506675791616 : 1
        140506684184320 : 1
        140506692577024 : 1
        140506700969728 : 3815
        140506784704256 : 1
        140506793096960 : 1
        140506801489664 : 3342
        140506809882368 : 1
        140506818275072 : 2846
        counter=10020
      ```
      可以看到与 std::lock_guard 的执行结果相似。
    + 执行场景 3 运行结果如下:
      ```shell
        sum=50005000
        140161820124928 : 498
        140161828517632 : 499
        140161912379136 : 495
        140161920771840 : 500
        140161929164544 : 502
        140161937557248 : 499
        140161945949952 : 502
        140161954342656 : 497
        140161962735360 : 504
        140162449250048 : 503
        140162457642752 : 500
        140162466035456 : 498
        140162474428160 : 501
        140162482820864 : 503
        140162491213568 : 500
        140162499606272 : 498
        140162578024192 : 507
        140162586416896 : 504
        140162594809600 : 509
        140162603202304 : 501
        counter=10020
      ```
      这个就比较符合预期，也就是说在生产场景下，正确的使用 std::unique_lock 可以更好地发挥多线程优势。
- 容易产生不均匀分配现象的另外一种场景 - 不正确的使用 std::unique_lock
    + std::unique_lock 与 std::cond_variable 联合使用场景
    + 典型的生产消费模型，生产者套接字线程负责向消息队列中读入消息；消费者消息处理线程负责从队列中读出消息进行处理；
    + 可能因为某些原因(如消费线程在处理某种消息时要占用较长时间，而此时 std::unique_lock 采用释放，即每次处理完一个消息才释放)，造成生产者线程中套接字读缓冲区积累了大量的待读入消息。生产者在获得锁之后，就会读入消息。虽然每读完一个消息都对锁进行了析构释放，但积压消息太多，生产者在释放锁之后，可能又会竞得这把锁，这样消费者线程就处于阻塞状态。
    + 知道了原因，也就很容易找到处理的办法，可以从以下方面着手:
        + 让生产者慢下来。生产者每次读入消息时，对消息队列长度进行判断，如果队列太长，可以主动将锁释放，休眠一会儿。这种处理比较复杂，很少使用；
        + 让消费者快一点。消费者从队列中取出一个消息后主动释放锁，而不是析构释放。这种处理简单，较常用。
        + 二者综合使用。

